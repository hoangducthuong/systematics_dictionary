\subsection{Time Constant Calibration Error (Kevin)}

\paragraph{Description:}
%Description of systematic effect, including relevant equations and parameterization for TWGs. Note that each variable in each equation should be defined. This should include where we expect to get the value of this variable from (TWG, literature, etc.)

Depending on the technique used to calibrate the thermal-response of the timestream, there might be several science scans taken in between calibration measurements. In between calibration measurements, the thermal calibration of each detector and its time constant can significantly drift from its initial value. Here sensitivity is defined at dP/dI and gain is defined as dT/dI or (dT/dP)*(dP/dI). Measurements of planets and known temperature sources like a stimulator give defined gain while studies of loopgain variation give sensitivity information. With a fixed voltage bias on a TES in the strong electrothermal feedback regime the total power on the detector is fixed so the electric bias power will change to compensate for changes in optical power: $\Delta P_{opt}=-\Delta P_{bias}$. The TES Loopgain, $\mathcal{L}$, is linearly proportional to $P_{bias}$ so as the detector sees changes in atmospheric and instrumental loading $\mathcal{L}$ varies. Although we are looking at gain stability here, the bolometers thermal time constant is also sped up under electrothermal feedback by the relationship (\ref{eq_timevar_1}) as given by Irwin \& Hilton \cite{Irwin_Hilton}. So variations in loopgain will effect both sensitivity and the time constant over an observation.
\begin{equation}
\label{eq_timevar_1}
\tau_{ETF}=\tau_0\frac{1+\beta_I+R_L/R_0}{1+\beta_I+R_L/R_0+(1-R_L/R_0)\mathcal{L}}
\end{equation}
$\tau_0$ is the intrinsic thermal time constant $G_0/C$. The power to current sensitivity (also called ``responsivity`` in ACT), $s_I(\omega)$ is also dependent on $\mathcal{L}$ and is given by (\ref{eq_timevar_1})
\begin{equation}
\label{eq_timevar_2}
s_I(\omega)=\frac{-1}{I_0R_0}\left(\frac{L}{\tau_{elec}R_0\mathcal{L}}+(1-\frac{R_L}{R_0})+i\omega\frac{L\tau_0}{R_0\mathcal{L}}(\frac{1}{\tau_{ETF}}+\frac{1}{\tau_{elec}})-\frac{\omega^2\tau_0L}{\mathcal{L}R_0}\right)^{-1}
\end{equation}
Where $R_0$ is the resistance on the transition where the bolometer is initially biased to, $R_L$ is the shunt resistor in parallel with the TES, $\tau_{elec}$ is the electrical time constant, $I_0$ is the required current to initially set the TES at $R_0$, and $L$ is the inductance in the TES bias/readout circuit, and $\beta_I$ is the logarithmic derivative of TES resistance with current. The limits that we typically take for our experiments is $R_L/R_0 \ll 1$, $\beta_I \ll 1$, $\tau{elec} \ll \tau_{ETF}$, and $\tau{elec} \ll \tau_0$. Taking this limit from (\ref{eq_timevar_1}), $\tau_{ETF} \simeq \frac{\tau_0}{\mathcal{L}+1}$, and $\tau_{elec} = \frac{L}{R_L+R_0}$. Equation (\ref{eq_timevar_2}) also reduces  significantly to (\ref{eq_timevar_3})
\begin{equation}
\label{eq_timevar_3}
s_I(\omega) \simeq \frac{-1}{V_{biax}}\left(\frac{\mathcal{L}}{\mathcal{L}+1}\right)\left(\frac{1}{1-i\omega\tau_{ETF}}\right)\left(\frac{1}{i\omega\tau_{elec}-1}\right)
\end{equation}
Since $\tau{elec} \ll \tau_0$, we often just consider a narrow frequency band around the carrier tone and ignore the second pole from the electric transfer function, so equation (\ref{eq_timevar_3}) can be written as (\ref{eq_timevar_4}).
\begin{equation}
\label{eq_timevar_4}
s_I(\omega) \simeq \frac{-1}{V_{biax}}\left(\frac{\mathcal{L}}{\mathcal{L}+1}\right)\left(\frac{1}{1-i\omega\tau_{ETF}}\right)
\end{equation}
To account for mean optical power drifts in time periods between rebiasing of the bolometer we must either come up with a model for how mean optical power is changing on these time scales or find a way to actively measure it so that we can calibrate out effects on responsivity and time-constants.

\paragraph{Plan to model and/or measure:}
%Plan to model/measure effect. Use SRFs to describe how well we understand/can model the effect. Is there a good null test that we could use to catch this effect?
A possible procedure to correct for time variation over the duration of a science scan is to interpolate our gains between measurements of the thermal calibration source taken at the beginning and end of the observation periods. To understand the impact of potential errors in this interpolation, we can construct a set of gains based only on the initial (or final) calibration measurement thus use no interpolation. Say now that a simulated map with no $B$-modes is ``observed,'' producing timestreams using the non-interpolated gain model, and then reconstructed using the interpolated analysis gain model.  The level of resulting \clbb\ (null to start with) quantifies the difference in these gain models in power spectrum space, and thus puts an upper limit on the impact of the drifts. Bias steps before/after observations, a stimulator, the HWP harmonics, and the atmosphere can all be used for time constant/gain corrections in time.

\textbf{SRF}

\paragraph{Uncertainty/Range:}
This section should include the uncertainty of
known parameters and/or the expected range of parameters for consideration

\paragraph{Parameterization:}
This section should include the parameterization of figures of
merit and the output to the SWGs.
